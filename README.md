![](LongBench/misc/logo.gif)
# ğŸ“š LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks

<p align="center">
    ğŸŒ <a href="https://longbench2.github.io" target="_blank">Project Page</a> â€¢ ğŸ“š <a href="https://arxiv.org/abs/2412.15204" target="_blank">LongBench v2 Paper</a> â€¢ ğŸ“Š <a href="https://huggingface.co/datasets/THUDM/LongBench-v2" target="_blank">LongBench v2 Dataset</a> â€¢ ğ• <a href="https://x.com/realYushiBai/status/1869946577349132766" target="_blank">Thread</a>
</p>
<p align="center">
    ğŸ“– <a href="https://arxiv.org/abs/2308.14508" target="_blank">LongBench Paper</a> â€¢ ğŸ¤— <a href="https://huggingface.co/datasets/THUDM/LongBench" target="_blank">LongBench Dataset</a>
</p>

---

## ğŸ“Œ Proje AÃ§Ä±klamasÄ±
Bu repoyu **LongBench v2** benchmark'Ä±nÄ± daha geniÅŸ bir model desteÄŸiyle Ã§alÄ±ÅŸtÄ±rmak ve analiz etmek iÃ§in fork ettim. Bu Ã§alÄ±ÅŸma, bÃ¼yÃ¼k dil modellerinin uzun baÄŸlamlardaki derin anlama ve akÄ±l yÃ¼rÃ¼tme yeteneklerini deÄŸerlendirmek amacÄ±yla gerÃ§ekleÅŸtirildi.

Bu sÃ¼rÃ¼mde **Gemini2.0 Flash Experimental** ve **Qwen2.5-14B-Instruct-1M** modelleri iÃ§in destek ekledim. **`pred.py`** dosyasÄ±nda yaptÄ±ÄŸÄ±m dÃ¼zenlemeler sayesinde, artÄ±k Gemini API'leriyle de uyumlu Ã§alÄ±ÅŸtÄ±rÄ±labilir.

ğŸ”— Orijinal repo: [THUDM/LongBenchv2](https://github.com/THUDM/LongBenchv2)

---

## âš™ï¸ Yeni Ã–zellikler ve GÃ¼ncellemeler

### Yeni Eklemeler:
1. **GeniÅŸletilmiÅŸ Model DesteÄŸi:**
   - **Gemini2.0 Flash Experimental** modeli iÃ§in destek eklendi.
   - **Qwen2.5-14B-Instruct-1M** modeliyle optimizasyonlar yapÄ±ldÄ±.

2. **`pred.py` GÃ¼ncellemeleri:**
   - VarsayÄ±lan olarak `--nproc 16` kullanÄ±lmakta. Ancak, API'ye aÅŸÄ±rÄ± yÃ¼klenmeyi Ã¶nlemek iÃ§in `--nproc 2` parametresiyle Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± Ã¶nerilir.
   - API Ã§aÄŸrÄ±larÄ±nda hata durumunda **otomatik yeniden deneme** mekanizmasÄ± eklendi.
   
3. **Analiz Ã‡Ä±ktÄ±larÄ±:**
   - **CoT (Chain-of-Thought) ile ve CoT olmadan** Ã§alÄ±ÅŸtÄ±rÄ±lan model sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±.

---

## ğŸ”¬ Deneysel Analizler

Bu Ã§alÄ±ÅŸmada **Gemini2.0 Flash Experimental** ve **Qwen2.5-14B-Instruct-1M** modelleri kullanÄ±ldÄ±. AÅŸaÄŸÄ±daki grafikler, **Chain-of-Thought (CoT) kullanÄ±larak ve kullanÄ±lmadan** yapÄ±lan deney sonuÃ§larÄ±nÄ± gÃ¶stermektedir:

### 1. CoT Olmadan SonuÃ§lar:
![CoT Olmadan](misc/experiment-without-cot.jpeg)

### 2. CoT ile SonuÃ§lar:
![CoT ile](misc/experiment-with-cot.jpeg)

**Not:** Qwen modeli daha kÃ¼Ã§Ã¼k bir parametre sayÄ±sÄ±na (14B) sahip olmasÄ±na raÄŸmen, diÄŸer bÃ¼yÃ¼k modellerle kÄ±yaslandÄ±ÄŸÄ±nda oldukÃ§a etkili sonuÃ§lar vermektedir.

---

## ğŸ“Š Performans Tablosu

AÅŸaÄŸÄ±da, LongBench v2 sÄ±ralamasÄ±na dair gÃ¼ncel performans sonuÃ§larÄ± paylaÅŸÄ±lmÄ±ÅŸtÄ±r. **Gemini2.0 Flash Experimental**, LongBench v2 liderlik tablosunda etkileyici bir sÄ±ralama elde etmiÅŸtir.

| Model                     | Params | Context  | Overall (%) | Easy (%) | Hard (%) | Short (%) | Medium (%) | Long (%) |
|---------------------------|--------|----------|-------------|----------|----------|-----------|------------|----------|
| Qwen2.5-14B (w/ CoT)     | 14B    | 1M       | 37.4        | 42.8     | 42.7     | 50.8      | 34.1       | 37.9     |
| Qwen2.5-14B (wo/ CoT)    | 14B    | 1M       | 29.0        | 35.5     | 33.0     | 41.3      | 29.0       | 29.0     |
| Gemini-2.0-Flash-Exp (w/ CoT) | 14B    | 1M       | 48.6        | 45.7     | 52.5     | 49.4      | 46.2       | 43.4     |
| Gemini-2.0-Flash-Exp (wo/ CoT)| 14B    | 1M       | 46.6        | 44.6     | 42.3     | 49.8      | 42.3       | 44.6     |

---

## âš™ï¸ KullanÄ±m TalimatlarÄ±

### Temel KullanÄ±m
```sh
python pred.py --model gpt-4 --save_dir results
```

### Ã–zel Ayarlar
Gemini ile Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
```sh
python pred.py --model gemini-2.0-flash-exp --nproc 2
```

Qwen modeli iÃ§in Ã¶zel bir API URL'si:
```sh
python pred.py --model qwen --base_url http://custom-url.com/v1
```

---

## ğŸ“ Ã‡Ä±ktÄ±lar

- Tahminler `.jsonl` formatÄ±nda kaydedilir.
- Ã‡Ä±ktÄ± Ã¶rneÄŸi:
  ```json
  {
    "_id": "123",
    "question": "What is AI?",
    "response": "AI stands for Artificial Intelligence.",
    "pred": "B",
    "judge": true
  }
  ```

---
